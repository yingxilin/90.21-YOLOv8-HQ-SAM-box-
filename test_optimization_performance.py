#!/usr/bin/env python3
"""
Box Refinement ä¼˜åŒ–æ€§èƒ½æµ‹è¯•è„šæœ¬
å¯¹æ¯”åŸå§‹ç‰ˆæœ¬å’Œä¼˜åŒ–ç‰ˆæœ¬çš„æ€§èƒ½å·®å¼‚
"""

import os
import sys
import time
import torch
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
import yaml
from typing import Dict, List, Tuple

# æ·»åŠ modulesç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'modules'))

from modules.box_refinement import BoxRefinementModule
from modules.hqsam_feature_extractor import create_hqsam_extractor
from train_box_refiner_optimized import FeatureCache, FungiDataset, extract_features_with_cache


class PerformanceTester:
    """æ€§èƒ½æµ‹è¯•å™¨"""
    
    def __init__(self, config_path: str, device: str = 'cuda'):
        self.device = device
        self.config_path = config_path
        
        # åŠ è½½é…ç½®
        with open(config_path, 'r') as f:
            self.config = yaml.safe_load(f)
        
        # åˆ›å»ºæ¨¡å‹å’Œç‰¹å¾æå–å™¨
        self.model = BoxRefinementModule(
            hidden_dim=self.config['model']['hidden_dim'],
            num_heads=self.config['model']['num_heads'],
            max_offset=self.config['model']['max_offset']
        ).to(device)
        
        self.hqsam_extractor = create_hqsam_extractor(
            checkpoint_path=self.config['hqsam']['checkpoint'],
            model_type=self.config['hqsam']['model_type'],
            device=device,
            use_mock=True  # ä½¿ç”¨Mockç‰ˆæœ¬è¿›è¡Œæµ‹è¯•
        )
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        self.test_images = self._create_test_images(10)  # 10å¼ æµ‹è¯•å›¾åƒ
        self.test_bboxes = self._create_test_bboxes(10)
    
    def _create_test_images(self, num_images: int) -> List[np.ndarray]:
        """åˆ›å»ºæµ‹è¯•å›¾åƒ"""
        images = []
        for i in range(num_images):
            # åˆ›å»ºéšæœºRGBå›¾åƒ
            image = np.random.randint(0, 255, (300, 300, 3), dtype=np.uint8)
            images.append(image)
        return images
    
    def _create_test_bboxes(self, num_bboxes: int) -> torch.Tensor:
        """åˆ›å»ºæµ‹è¯•bbox"""
        bboxes = []
        for i in range(num_bboxes):
            # åˆ›å»ºéšæœºbbox [x1, y1, x2, y2]
            x1 = np.random.randint(0, 200)
            y1 = np.random.randint(0, 200)
            x2 = x1 + np.random.randint(50, 100)
            y2 = y1 + np.random.randint(50, 100)
            bboxes.append([x1, y1, x2, y2])
        return torch.tensor(bboxes, dtype=torch.float32, device=self.device)
    
    def test_original_approach(self) -> Dict[str, float]:
        """æµ‹è¯•åŸå§‹æ–¹æ³• (æ¯æ¬¡éƒ½æå–ç‰¹å¾)"""
        print("æµ‹è¯•åŸå§‹æ–¹æ³•...")
        
        start_time = time.time()
        
        # æ¨¡æ‹ŸåŸå§‹è®­ç»ƒè¿‡ç¨‹
        for epoch in range(3):  # 3ä¸ªepoch
            for batch_idx in range(5):  # 5ä¸ªbatch
                # æ¯æ¬¡éƒ½è¦æå–ç‰¹å¾
                features_list = []
                for image in self.test_images:
                    features = self.hqsam_extractor.extract_features(image)
                    features_list.append(features)
                
                # æ¨¡æ‹Ÿå‰å‘ä¼ æ’­
                image_features = torch.cat(features_list, dim=0)
                bboxes = self.test_bboxes[:len(features_list)]
                
                with torch.no_grad():
                    refined_bboxes, _ = self.model.iterative_refine(
                        image_features, bboxes, (300, 300),
                        max_iter=self.config['refinement']['max_iter']
                    )
        
        end_time = time.time()
        total_time = end_time - start_time
        
        return {
            'total_time': total_time,
            'avg_epoch_time': total_time / 3,
            'avg_batch_time': total_time / (3 * 5),
            'feature_extractions': 3 * 5 * len(self.test_images)
        }
    
    def test_optimized_approach(self) -> Dict[str, float]:
        """æµ‹è¯•ä¼˜åŒ–æ–¹æ³• (ä½¿ç”¨ç¼“å­˜)"""
        print("æµ‹è¯•ä¼˜åŒ–æ–¹æ³•...")
        
        # åˆ›å»ºç‰¹å¾ç¼“å­˜
        cache_dir = "./test_features"
        feature_cache = FeatureCache(cache_dir, 'test')
        
        start_time = time.time()
        
        # æ¨¡æ‹Ÿä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹
        for epoch in range(3):  # 3ä¸ªepoch
            for batch_idx in range(5):  # 5ä¸ªbatch
                # ä½¿ç”¨ç¼“å­˜æå–ç‰¹å¾
                image_paths = [f"test_image_{i}.jpg" for i in range(len(self.test_images))]
                features_list = extract_features_with_cache(
                    self.hqsam_extractor, self.test_images, image_paths, feature_cache
                )
                
                # æ¨¡æ‹Ÿå‰å‘ä¼ æ’­
                image_features = torch.cat(features_list, dim=0)
                bboxes = self.test_bboxes[:len(features_list)]
                
                with torch.no_grad():
                    refined_bboxes, _ = self.model.iterative_refine(
                        image_features, bboxes, (300, 300),
                        max_iter=self.config['refinement']['max_iter']
                    )
        
        end_time = time.time()
        total_time = end_time - start_time
        
        # è·å–ç¼“å­˜ç»Ÿè®¡
        cache_stats = feature_cache.get_cache_stats()
        
        return {
            'total_time': total_time,
            'avg_epoch_time': total_time / 3,
            'avg_batch_time': total_time / (3 * 5),
            'feature_extractions': 3 * 5 * len(self.test_images),
            'cache_hit_rate': cache_stats['hit_rate'],
            'cache_hits': cache_stats['hits'],
            'cache_misses': cache_stats['misses']
        }
    
    def test_data_sampling(self) -> Dict[str, float]:
        """æµ‹è¯•æ•°æ®æŠ½æ ·æ•ˆæœ"""
        print("æµ‹è¯•æ•°æ®æŠ½æ ·æ•ˆæœ...")
        
        # åˆ›å»ºå¤§æ•°æ®é›†
        large_dataset = FungiDataset(
            data_root=self.config['data']['data_root'],
            split=self.config['data']['train_split'],
            image_size=self.config['data']['image_size'],
            data_subset=self.config['data']['data_subset'],
            augmentation=False,
            debug=True,  # ä½¿ç”¨è°ƒè¯•æ¨¡å¼
            sample_ratio=None  # ä¸ä½¿ç”¨æŠ½æ ·
        )
        
        # åˆ›å»ºæŠ½æ ·æ•°æ®é›†
        sampled_dataset = FungiDataset(
            data_root=self.config['data']['data_root'],
            split=self.config['data']['train_split'],
            image_size=self.config['data']['image_size'],
            data_subset=self.config['data']['data_subset'],
            augmentation=False,
            debug=True,  # ä½¿ç”¨è°ƒè¯•æ¨¡å¼
            sample_ratio=0.1  # 10%æŠ½æ ·
        )
        
        return {
            'full_dataset_size': len(large_dataset),
            'sampled_dataset_size': len(sampled_dataset),
            'sampling_ratio': len(sampled_dataset) / len(large_dataset),
            'reduction_factor': len(large_dataset) / len(sampled_dataset)
        }
    
    def test_mixed_precision(self) -> Dict[str, float]:
        """æµ‹è¯•æ··åˆç²¾åº¦è®­ç»ƒæ•ˆæœ"""
        print("æµ‹è¯•æ··åˆç²¾åº¦è®­ç»ƒæ•ˆæœ...")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        batch_size = 8
        images = torch.randn(batch_size, 3, 300, 300, device=self.device)
        bboxes = torch.randn(batch_size, 4, device=self.device)
        image_features = torch.randn(batch_size, 256, 64, 64, device=self.device)
        
        # æµ‹è¯•æ™®é€šç²¾åº¦
        start_time = time.time()
        for _ in range(100):
            with torch.no_grad():
                refined_bboxes, _ = self.model.iterative_refine(
                    image_features, bboxes, (300, 300),
                    max_iter=self.config['refinement']['max_iter']
                )
        normal_time = time.time() - start_time
        
        # æµ‹è¯•æ··åˆç²¾åº¦
        start_time = time.time()
        for _ in range(100):
            with torch.no_grad():
                with torch.cuda.amp.autocast():
                    refined_bboxes, _ = self.model.iterative_refine(
                        image_features, bboxes, (300, 300),
                        max_iter=self.config['refinement']['max_iter']
                    )
        amp_time = time.time() - start_time
        
        return {
            'normal_time': normal_time,
            'amp_time': amp_time,
            'speedup': normal_time / amp_time,
            'memory_saved': '~30-50%'  # ä¼°ç®—å€¼
        }
    
    def run_all_tests(self) -> Dict[str, Dict[str, float]]:
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹æ€§èƒ½æµ‹è¯•...")
        print("=" * 50)
        
        results = {}
        
        # æµ‹è¯•åŸå§‹æ–¹æ³•
        try:
            results['original'] = self.test_original_approach()
        except Exception as e:
            print(f"åŸå§‹æ–¹æ³•æµ‹è¯•å¤±è´¥: {e}")
            results['original'] = {}
        
        # æµ‹è¯•ä¼˜åŒ–æ–¹æ³•
        try:
            results['optimized'] = self.test_optimized_approach()
        except Exception as e:
            print(f"ä¼˜åŒ–æ–¹æ³•æµ‹è¯•å¤±è´¥: {e}")
            results['optimized'] = {}
        
        # æµ‹è¯•æ•°æ®æŠ½æ ·
        try:
            results['sampling'] = self.test_data_sampling()
        except Exception as e:
            print(f"æ•°æ®æŠ½æ ·æµ‹è¯•å¤±è´¥: {e}")
            results['sampling'] = {}
        
        # æµ‹è¯•æ··åˆç²¾åº¦
        try:
            results['mixed_precision'] = self.test_mixed_precision()
        except Exception as e:
            print(f"æ··åˆç²¾åº¦æµ‹è¯•å¤±è´¥: {e}")
            results['mixed_precision'] = {}
        
        return results
    
    def print_results(self, results: Dict[str, Dict[str, float]]):
        """æ‰“å°æµ‹è¯•ç»“æœ"""
        print("\nğŸ“Š æ€§èƒ½æµ‹è¯•ç»“æœ")
        print("=" * 50)
        
        # åŸå§‹ vs ä¼˜åŒ–å¯¹æ¯”
        if 'original' in results and 'optimized' in results:
            orig = results['original']
            opt = results['optimized']
            
            if 'total_time' in orig and 'total_time' in opt:
                speedup = orig['total_time'] / opt['total_time']
                print(f"\nğŸ”„ ç‰¹å¾ç¼“å­˜æ•ˆæœ:")
                print(f"  åŸå§‹æ–¹æ³•æ€»æ—¶é—´: {orig['total_time']:.2f}s")
                print(f"  ä¼˜åŒ–æ–¹æ³•æ€»æ—¶é—´: {opt['total_time']:.2f}s")
                print(f"  åŠ é€Ÿæ¯”: {speedup:.1f}x")
                
                if 'cache_hit_rate' in opt:
                    print(f"  ç¼“å­˜å‘½ä¸­ç‡: {opt['cache_hit_rate']:.1%}")
                    print(f"  ç¼“å­˜å‘½ä¸­: {opt['cache_hits']}")
                    print(f"  ç¼“å­˜æœªå‘½ä¸­: {opt['cache_misses']}")
        
        # æ•°æ®æŠ½æ ·æ•ˆæœ
        if 'sampling' in results:
            samp = results['sampling']
            print(f"\nğŸ“‰ æ•°æ®æŠ½æ ·æ•ˆæœ:")
            print(f"  å®Œæ•´æ•°æ®é›†å¤§å°: {samp.get('full_dataset_size', 'N/A')}")
            print(f"  æŠ½æ ·æ•°æ®é›†å¤§å°: {samp.get('sampled_dataset_size', 'N/A')}")
            print(f"  æŠ½æ ·æ¯”ä¾‹: {samp.get('sampling_ratio', 0):.1%}")
            print(f"  æ•°æ®å‡å°‘å€æ•°: {samp.get('reduction_factor', 1):.1f}x")
        
        # æ··åˆç²¾åº¦æ•ˆæœ
        if 'mixed_precision' in results:
            mp = results['mixed_precision']
            print(f"\nâš¡ æ··åˆç²¾åº¦æ•ˆæœ:")
            print(f"  æ™®é€šç²¾åº¦æ—¶é—´: {mp.get('normal_time', 0):.2f}s")
            print(f"  æ··åˆç²¾åº¦æ—¶é—´: {mp.get('amp_time', 0):.2f}s")
            print(f"  åŠ é€Ÿæ¯”: {mp.get('speedup', 1):.1f}x")
            print(f"  æ˜¾å­˜èŠ‚çœ: {mp.get('memory_saved', 'N/A')}")
        
        # ç»¼åˆæ•ˆæœä¼°ç®—
        print(f"\nğŸ¯ ç»¼åˆä¼˜åŒ–æ•ˆæœä¼°ç®—:")
        feature_speedup = results.get('original', {}).get('total_time', 1) / results.get('optimized', {}).get('total_time', 1)
        sampling_speedup = results.get('sampling', {}).get('reduction_factor', 1)
        amp_speedup = results.get('mixed_precision', {}).get('speedup', 1)
        
        total_speedup = feature_speedup * sampling_speedup * amp_speedup
        print(f"  ç‰¹å¾ç¼“å­˜åŠ é€Ÿ: {feature_speedup:.1f}x")
        print(f"  æ•°æ®æŠ½æ ·åŠ é€Ÿ: {sampling_speedup:.1f}x")
        print(f"  æ··åˆç²¾åº¦åŠ é€Ÿ: {amp_speedup:.1f}x")
        print(f"  ç»¼åˆåŠ é€Ÿæ¯”: {total_speedup:.1f}x")
        
        if total_speedup >= 30:
            print("  âœ… è¾¾åˆ°ç›®æ ‡: â‰¥30x åŠ é€Ÿ")
        else:
            print("  âš ï¸  æœªè¾¾åˆ°ç›®æ ‡: <30x åŠ é€Ÿ")
    
    def save_results(self, results: Dict[str, Dict[str, float]], filename: str = "performance_test_results.txt"):
        """ä¿å­˜æµ‹è¯•ç»“æœåˆ°æ–‡ä»¶"""
        with open(filename, 'w') as f:
            f.write("Box Refinement æ€§èƒ½æµ‹è¯•ç»“æœ\n")
            f.write("=" * 50 + "\n\n")
            
            for test_name, test_results in results.items():
                f.write(f"{test_name.upper()} æµ‹è¯•ç»“æœ:\n")
                for key, value in test_results.items():
                    f.write(f"  {key}: {value}\n")
                f.write("\n")
        
        print(f"\nğŸ’¾ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {filename}")


def main():
    """ä¸»å‡½æ•°"""
    print("Box Refinement æ€§èƒ½æµ‹è¯•å·¥å…·")
    print("=" * 50)
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    config_path = "configs/box_refinement_config.yaml"
    if not Path(config_path).exists():
        print(f"é”™è¯¯: é…ç½®æ–‡ä»¶ {config_path} ä¸å­˜åœ¨!")
        return
    
    # æ£€æŸ¥è®¾å¤‡
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    if device == 'cpu':
        print("è­¦å‘Š: ä½¿ç”¨CPUå¯èƒ½å½±å“æµ‹è¯•ç»“æœçš„å‡†ç¡®æ€§")
    
    # åˆ›å»ºæµ‹è¯•å™¨
    tester = PerformanceTester(config_path, device)
    
    # è¿è¡Œæµ‹è¯•
    results = tester.run_all_tests()
    
    # æ‰“å°ç»“æœ
    tester.print_results(results)
    
    # ä¿å­˜ç»“æœ
    tester.save_results(results)
    
    print("\nâœ… æ€§èƒ½æµ‹è¯•å®Œæˆ!")


if __name__ == "__main__":
    main()